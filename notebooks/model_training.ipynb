{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction Crack Detection - Model Training\n",
    "\n",
    "This notebook demonstrates the process of training a deep learning model for crack detection in construction images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "from crackdetect.models.segmentation import UNet\n",
    "from crackdetect.data.dataset import CrackDataset\n",
    "from crackdetect.data.augmentation import get_training_augmentation, get_validation_augmentation\n",
    "from crackdetect.training.losses import combo_loss\n",
    "from crackdetect.training.metrics import iou_score, dice_coefficient\n",
    "from crackdetect.training.trainer import Trainer\n",
    "from config.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Let's set up the configuration for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Override some parameters for the notebook\n",
    "config.batch_size = 4\n",
    "config.num_epochs = 10  # Use a small number for demonstration\n",
    "config.models_dir = Path(\"../saved_models\")\n",
    "config.models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Let's prepare the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "data_dir = Path(\"../data\")\n",
    "train_dir = data_dir / \"train\"\n",
    "val_dir = data_dir / \"val\"\n",
    "\n",
    "# Get augmentations\n",
    "train_transform = get_training_augmentation(height=config.image_size[0], width=config.image_size[1])\n",
    "val_transform = get_validation_augmentation(height=config.image_size[0], width=config.image_size[1])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CrackDataset(\n",
    "    image_dir=train_dir / \"images\",\n",
    "    mask_dir=train_dir / \"masks\",\n",
    "    image_size=config.image_size,\n",
    "    transform=train_transform,\n",
    "    preprocessing=True\n",
    ")\n",
    "\n",
    "val_dataset = CrackDataset(\n",
    "    image_dir=val_dir / \"images\",\n",
    "    mask_dir=val_dir / \"masks\",\n",
    "    image_size=config.image_size,\n",
    "    transform=val_transform,\n",
    "    preprocessing=True\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Training Samples\n",
    "\n",
    "Let's visualize some training samples to verify our data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "train_batch = next(iter(train_loader))\n",
    "images = train_batch['image']\n",
    "masks = train_batch['mask']\n",
    "\n",
    "# Visualize batch\n",
    "fig, axes = plt.subplots(config.batch_size, 2, figsize=(10, 5*config.batch_size))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(config.batch_size):\n",
    "    # Convert from tensor to numpy\n",
    "    image = images[i].permute(1, 2, 0).numpy()\n",
    "    mask = masks[i, 0].numpy()\n",
    "    \n",
    "    # Display images\n",
    "    axes[i, 0].imshow(image)\n",
    "    axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Mask {i+1}\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Initialization\n",
    "\n",
    "Let's initialize the UNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "# Print model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, config.image_size[0], config.image_size[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Setup\n",
    "\n",
    "Let's set up the training components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# Create learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=combo_loss,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=scheduler,\n",
    "    num_epochs=config.num_epochs,\n",
    "    save_dir=config.models_dir,\n",
    "    model_name=\"crack_segmentation_notebook\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Results\n",
    "\n",
    "Let's visualize the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "epochs = range(1, config.num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, history['train_losses'], 'b-', label='Training Loss')\n",
    "plt.plot(epochs, history['val_losses'], 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, history['val_ious'], 'g-')\n",
    "plt.title('Validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, history['val_dices'], 'm-')\n",
    "plt.title('Validation Dice')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.models_dir / \"training_history.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prediction Visualization\n",
    "\n",
    "Let's visualize some predictions from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model_path = config.models_dir / \"crack_segmentation_notebook_best.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of validation data\n",
    "val_batch = next(iter(val_loader))\n",
    "images = val_batch['image'].to(device)\n",
    "masks = val_batch['mask']\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    preds = (outputs > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(config.batch_size, 3, figsize=(15, 5*config.batch_size))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(config.batch_size):\n",
    "    # Convert from tensor to numpy\n",
    "    image = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "    mask = masks[i, 0].numpy()\n",
    "    pred = preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate IoU for this prediction\n",
    "    pred_tensor = torch.tensor(pred).unsqueeze(0).unsqueeze(0)\n",
    "    mask_tensor = torch.tensor(mask).unsqueeze(0).unsqueeze(0)\n",
    "    iou = iou_score(pred_tensor, mask_tensor).item()\n",
    "    dice = dice_coefficient(pred_tensor, mask_tensor).item()\n",
    "    \n",
    "    # Display images\n",
    "    axes[i, 0].imshow(image)\n",
    "    axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title(f\"True Mask\")\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f\"Prediction (IoU: {iou:.4f}, Dice: {dice:.4f})\")\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Crack Analysis\n",
    "\n",
    "Let's analyze the detected cracks using our CrackAnalyzer tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crackdetect.utils.crack_analysis import CrackAnalyzer\n",
    "from crackdetect.inference.visualization import create_result_figure\n",
    "\n",
    "# Initialize crack analyzer\n",
    "analyzer = CrackAnalyzer(pixel_mm_ratio=0.1)  # Adjust the pixel_mm_ratio as needed\n",
    "\n",
    "# Select an image from the validation set\n",
    "sample_idx = 0\n",
    "image = images[sample_idx].cpu().permute(1, 2, 0).numpy()\n",
    "pred = preds[sample_idx, 0].cpu().numpy()\n",
    "\n",
    "# Analyze cracks\n",
    "crack_properties = analyzer.analyze_mask(pred, min_area=100)\n",
    "\n",
    "# Visualize results\n",
    "result_image = analyzer.visualize_analysis(image, pred, crack_properties)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(pred, cmap='gray')\n",
    "axes[1].set_title(\"Predicted Mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(result_image)\n",
    "axes[2].set_title(\"Crack Analysis\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print crack properties\n",
    "print(f\"Number of cracks detected: {len(crack_properties)}\")\n",
    "for i, props in enumerate(crack_properties):\n",
    "    print(f\"\\nCrack #{i+1}:\")\n",
    "    print(f\"  Severity: {props.severity}\")\n",
    "    print(f\"  Average Width: {props.width_avg:.2f} mm\")\n",
    "    print(f\"  Maximum Width: {props.width_max:.2f} mm\")\n",
    "    print(f\"  Length: {props.length:.2f} mm\")\n",
    "    print(f\"  Area: {props.area:.2f} mm²\")\n",
    "    print(f\"  Orientation: {props.orientation:.1f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Export\n",
    "\n",
    "Finally, let's export the trained model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in production format\n",
    "final_model_path = config.models_dir / \"crack_detection_final.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "\n",
    "# Print instructions for using the model\n",
    "print(\"\\nTo use the model for prediction, run:\")\n",
    "print(f\"python scripts/predict.py --image path/to/image.jpg --model {final_model_path} --output results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}